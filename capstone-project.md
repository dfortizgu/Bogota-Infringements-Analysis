# Google Capstone Project

## Ask
Five questions will guide your case study: 

1. What type of company does your client represent, and what are they asking you to accomplish?
2. What are the key factors involved in the business task you are investigating?
3. What type of data will be appropriate for your analysis?
4. Where will you obtain that data?
5. Who is your audience, and what materials will help you present to them effectively?

**Answers:**
1. My client is the government of Bogotá (capital of Colombia), who want to extract valuable information from infringements data in the city to implement better mobility strategies.
2. The infringements data in Bogotá for the year 2015 and 2021. A proper understanding of the geospatial data and its proper manipulation.
3. Geospatial data obtained from the data provided by the police, which provides information about the kind of infringements happened in Bogotá those years
4. From the open data center of the District Secretary of Mobility of Bogotá. It's [web page](https://datos.movilidadbogota.gov.co/).
5. I want to inspect the main infringement behavior over time in the city.


**Guiding questions** 
| Question                                                                  | Answer                                                                                                                                                |
| ------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| What topic are you exploring?                                             | Accidents and infringments in Bogotá                                                                                                            |
| What is the problem you are trying to solve                               | What are the main areas of accidents and infringments in Bogotá?                                                                                      |
| What metrics will you use to measure your data to achieve your objective? | Latitude and longitude data mainly                                                                                                                            |
| How can your insights help your client make decisions?                    | Knowing the main areas of accidents in the city could implement a better response strategy in this events |



**Key tasks:**
| Task                       | Answer                                                                                                                                                                                                                                                                     |
| -------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Identify the bussines task | Answer the question: Whats is the distribution infringments in Bogotá                                                                                                                                                                                     |
| Determine the stakeholders | The people in charge of implementing new policies for infringement managent                                                                                                                                                       |
| Choose a dataset           | All files, original ones an changes allong the process can be founf [here](https://drive.google.com/drive/folders/1F1dWfuO1ewgBrsvucCtswx2uwG-lOPrh?usp=sharing) . The files named "Comparendos_20XX_Bogota.csv" are the original files |

## Process for the Infringements Data

1. As part of the data cleaning process, some mistakes in the data format of the csv files downloaded from the original source are solved. The errors consisted of line jumps along the file that changed the structure of the csv table. For correcting this, a python script is used ([[python_for_data_manipulation.ipynb]].) The process is explained in the script. In total, 114760 wrong lines are corrected.

2. In R studio, the [[R Analisys.Rmd]] file is created. In this are implemented some more data cleaning:
	- The column names are standardized among all infringements files. 
	- For the 2020 infringements, the original file is lacking the LOCALIDAD (location name) field. For filling this, we use the [[georeferencia-puntual-por-localidad.csv]] file, which contains the central longitude and latitude for each location (This file was generated by hand, finding the central point for each location in google maps, since the coordinates found in the web for this locations in other datasets does not match the real location some times). The closest location for each data point is found calculating its [great circle distance](https://en.wikipedia.org/wiki/Great-circle_distance) for each location coordinates and getting the location with the least distance. This aproach is only an aproximation to the location, a more complete analisys would require finding the coordinates for the polygon that descrive each location in the map, but this is aout of scope for this analisys for the moment. The problem with this aproximation take place in the frontier between two locations, but it is the best way for now.
	- The common columns and the ones of interest once the lacking data in the 2020 file is filled are:
		- LONGITUDE
		- LATITUDE
		- OBJECTID (Unique Identifier)
		- FECHA_HORA (Date and Hour)
		- MEDIO_DETECCION (Detection medium)
		- CLASE_VEHICULO (Kind of vehicle)
		- TIPO_SERVICIO (Kind of service)
		- INFRACCION (Infringement)
		- DES_INFRACCION (Infringment description)
		- LOCALIDAD (Location)
	-  A single .csv file is created containing all the information of interest for the year 2015-2021 ([[infringements_2015_2021.csv]]). This file is ready for making some final cleaning and filtering with BigQuery
	
3. The file for infringements 2015-2021 is uploaded to Google Drive and imported from there to BigQuery (BigQuery does not allow uploading files heavier than 10MB  via web UI), then a copy of that table was made (since BigQuery does not allow editing external files, like the ones imported from Drive) for editing. Once there the changes made to that copy are
	- Standardize the LOCALIDAD (locations) field: Among the different files we found different ways of writing each location, like with Teusaquillo which was written like TEUSAQUILLO, TEUSAQUÍLLO, 1-TEUSAQUILLO and 1-TEUSAQUÍLLO. It happened with all locations. The standard names used are  `code-name`, extracted from the [[georeferencia-puntual-por-localidad.csv | locations reference]]. The query used for that is written in this .sql file [[script1.sql]]
	- Once the locations are standardized, some missing data in that field is found. It was not seen as before in the R file, since the column for location existed in the files except for the one for 2020. Are empty cells, not a whole variable missing. For filling these cells, we consider the same approach made for the 2020 file (assign the location by the closest location center given by the [[georeferencia-puntual-por-localidad.csv | locations reference]]). This time, considering the slow performance in this task in the R script, the strategy is implemented directly in BigQuery
	- With the script [[script2.sql]] a new table is created (manually created the table with name correct_loc_infringements in BigQuery once executed the script), this tables contains the approximate location for each row in a new column. Then the new tables is modified with [[script3.sql]] to replace the cell with " ", "-", "Otro",  “BOGOTA D.C." or "Field was not enabled”  as original locations and put there the approximate location. Then the additional column is dropped.
	- The kind of vehicle is standardized, correcting some errors and making all cells uppercase.  Also the detection mean is put in uppercase as well as the kind of service (with a few corrections). The script for all this changes is [[script4.sql]], which was applied to modifie the last table correct_loc_infringements.
	- In the description of each infringement (DES_INFRACCION) were found multiple grammatical errors, for correcting this, a file that correlates the infringement code (INFRACCION) and the description was download from the transportation ministry web site [here](https://www.mintransporte.gov.co/descargar.php?id=2598). This file was modified to generate an adequate csv file ([[tabla_comparendos.csv]]) for uploading  to BigQuery (the table was called ref_infringement). Once uploaded, the finall cleaning process is made with the query shown in [[script5.sql]]. The result of this query is saved in the table clean_infringements.  

4. A complete dashboard showing some information and relations extracted from the final data file is implemented in tableau. The visualizations can be seen [here](https://public.tableau.com/app/profile/david.francisco/viz/dashboard_infringements/Dashboard1?publish=yes)
 	